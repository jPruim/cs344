{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proposal.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjfP9zpj4J1YOXRKUKzhFQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jPruim/cs344/blob/master/finalproject/proposal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20mrJTshVV6o",
        "colab_type": "text"
      },
      "source": [
        "The goal of this project is to use neural networks to try and solve common linear algebra problems. This will involve using neural nets and CNN's to try and see how few nodes are necessary to solve some problems, and how accurately I can find these values.\n",
        "\n",
        "Specifically I hope to investigate determinants and eigenvalues for matrices. Determinants are single unique values for a given matrix. A determinant can describe properties such as whether the matrix is invertable or not. Should the determinant be zero, then there is no inverse of the matrix. This creates a whole area of linear algebra where people investigate extensions of inverses to all matrices (e.g. Penrose-Moore inverse). Eigenvalues are a very common measurement use in physics. It becomes important to get eigenvalues from matrices to see how forcing changes a system. Eigenvalues are also the basis of many different types of matrix decompositions. Similarly, eigenvalues are prevalent throughout the solving of various differential equations. Overall, they might be the single most interesting derived values from a given matrix.\n",
        "\n",
        "This project will be used to determine how well a NN can approximate these values. Mostly, this project is to satisfy personal curiosity in the complexity of finding these values. If they prove hard or impossible to approximate, it shows a more significant difference between the creativity of the human mind and the computational power of a computer.\n",
        "\n",
        "\n",
        "Some background info:\n",
        "CNN, allows for first analyzing just part of the input before expanding to the whole matrix\n",
        "leaky ReLU, Tanh, both to counter dead neural networks\n",
        "\n",
        "Implementation:\n",
        "Just use the differing simple an CNN models to try and fit random normalized matrices.\n",
        "\n",
        "Results:\n",
        "I am starting to wonder if this is possible...\n",
        "\n",
        "Implications:\n",
        "If it's possible, then I guess thats cool.\n",
        "If it's not, then there are cool implications on the limitations of neural networks, this would seem to indicate that the human mind is somewhat unique in its way of finding algorithms and making connections between numerical input.\n",
        "\n",
        "\n"
      ]
    }
  ]
}