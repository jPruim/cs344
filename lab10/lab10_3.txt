

learning_rate=0.01,
steps=100,
batch_size=20,
Final accuracy (on validation data): 0.83


The confusion matrix shows which classes were misclassified as other classes. Which digits get confused for each other?

# Caution: input pipelines are reset with each call to train. 
# If the number of steps is small, your model may never see most of the data.  
# So with multiple `.train` calls like this you may want to control the length 
# of training with num_epochs passed to the input_fn. Or, you can do a really-big shuffle, 
# or since it's in-memory data, shuffle all the data in the `input_fn`. --google.
This would be the difference. 
Accuracy on test data: 0.95


It seemed to me, that the lower step sizes has more images with coarser grain. 
However, the coarser step size also seems to have a horrible confusion matrix as well, so I am not sure how good the model is at this point. The images also seem to change more between an image and the next.
Accuracy on test data: 0.47
