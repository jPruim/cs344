This was not well described anywhere (and we are covering it in class on monday). But I assume this has to do with the loss regulation equation I found online. This overall results in a better adjustment to learning rate as it progresses.
Bucketing allows the data to turn continuous or verbal (such as color) arguments into a discrete data set for datafitting. This can allow for better fittings, especially if for example the buckets are those beneath poverty. Middle class, and upperclass for income.

 # Divide households into 7 buckets.
  bucketized_households = tf.feature_column.bucketized_column(
    households, boundaries=get_quantile_based_boundaries(
      training_examples["households"], 7))

  # Divide longitude into 10 buckets.
  bucketized_longitude = tf.feature_column.bucketized_column(
    longitude, boundaries=get_quantile_based_boundaries(
      training_examples["longitude"], 10))
  
  bucketized_latitude = tf.feature_column.bucketized_column(
    latitude, boundaries=get_quantile_based_boundaries(
      training_examples["latitude"], 7))


  bucketized_housing_median_age = tf.feature_column.bucketized_column(
    housing_median_age, boundaries=get_quantile_based_boundaries(
      training_examples["housing_median_age"], 7))
  
  bucketized_median_income = tf.feature_column.bucketized_column(
    median_income, boundaries=get_quantile_based_boundaries(
      training_examples["median_income"], 7))
  
  bucketized_rooms_per_person = tf.feature_column.bucketized_column(
    rooms_per_person, boundaries=get_quantile_based_boundaries(
      training_examples["rooms_per_person"], 7))



From solution, I couldn't figure out a clean way of doing this.

 long_x_lat = tf.feature_column.crossed_column(
  set([bucketized_longitude, bucketized_latitude]), hash_bucket_size=1000) 


  This latxlong bucketing will result in price rising due to being in different cities. For example, NYC apartments cost more than Wymoning apartments, even if everything else is the same.
